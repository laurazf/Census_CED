{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse as ulp\n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "host=\"web5.ces.census.gov\",\n",
    "user=\"##\",\n",
    "password=\"##\",\n",
    "database=\"pmt\"\n",
    ")\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "sql = \"SET collation_connection = 'utf8_general_ci'\"\n",
    "mycursor.execute(sql)\n",
    "mydb.commit()\n",
    "sql1 = \"ALTER TABLE api_core CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci\"\n",
    "mycursor.execute(sql1)\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://doaj.org/api/v2/search/articles/%22Jack%20Johnson%22?page=1&pageSize=10\n",
    "\n",
    "class DOAJ:\n",
    "    \n",
    "    def sendToDB(self, proj_id, results, hits):\n",
    "        #print(proj_id)\n",
    "        mydb = mysql.connector.connect(\n",
    "        host=\"web5.ces.census.gov\",\n",
    "        user=\"##\",\n",
    "        password=\"##\",\n",
    "        database=\"pmt\"\n",
    "        )\n",
    "\n",
    "        mycursor = mydb.cursor()\n",
    "        \n",
    "        numPrint = 100\n",
    "        if(hits < 100):\n",
    "            numPrint = hits\n",
    "        #print(\"numPrint = \" + str(numPrint))\n",
    "        for i in range(numPrint):\n",
    "            title = str(results['results'][i]['bibjson']['title'])\n",
    "            doi_array = results['results'][i]['bibjson']['identifier']\n",
    "            res = next((sub for sub in doi_array if sub['type'] == 'doi'), None)\n",
    "            doi = res['id']\n",
    "            authors = results['results'][i]['bibjson9author']\n",
    "            pub_year = str(results['results'][i]['bibjson']['year'])\n",
    "            pub_month = str(results['results'][i]['bibjson']['month'])\n",
    "            keywords = str(results['results'][i]['bibjson'].get('keywords'))\n",
    "            abstract = str(results['results'][i]['bibjson']['abstract'])\n",
    "            full_text_url = str(results['results'][i]['bibjson']['link'][0]['url'])\n",
    "            \n",
    "            sql_dup = \"SELECT * FROM api_doaj WHERE title = %s AND abstract = %s AND proj_id = %s\"\n",
    "            data = (title, abstract, proj_id, )\n",
    "            mycursor.execute(sql_dup, data)\n",
    "            duplicates = mycursor.fetchall()\n",
    "\n",
    "            if len(duplicates) == 0:\n",
    "                sql = \"INSERT INTO api_doaj (proj_id, title, doi, pub_year, pub_month, keywords, abstract, full_text_url) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "                val = (proj_id, title, doi, pub_year, pub_month, keywords, abstract, full_text_url)\n",
    "                \n",
    "                mycursor.execute(sql, val)\n",
    "                pub_id = mycursor.lastrowid\n",
    "                print(\"pub_id: \" +str(pub_id))\n",
    "\n",
    "                mydb.commit()\n",
    "\n",
    "                print(mycursor.rowcount, \"record inserted.\")\n",
    "\n",
    "                for j in range(len(author)):\n",
    "                    sql_part = \"INSERT INTO api_doaj_participants (pub_id, proj_id, fullname) VALUES (%s, %s, %s)\"\n",
    "                    val_part = (pub_id, proj_id, author[j])\n",
    "\n",
    "                    mycursor.execute(sql_part, val_part)\n",
    "\n",
    "                    mydb.commit()\n",
    "\n",
    "                    print(mycursor.rowcount, \"participant record inserted.\")\n",
    "                    \n",
    "            else:\n",
    "                print(\"duplicate value, not added\")\n",
    "                \n",
    "        sql_update_doi = \"UPDATE api_doaj SET doi=NULL WHERE doi='None'\"\n",
    "        mycursor.execute(sql_update_doi)\n",
    "        mydb.commit()\n",
    "        sql_update_title = \"UPDATE api_doaj SET title=NULL WHERE title='None'\"\n",
    "        mycursor.execute(sql_update_title)\n",
    "        mydb.commit()\n",
    "        print(\"changed None values to null in doi, title\")\n",
    "        \n",
    "class DOAJSearch(DOAJ):\n",
    "    \n",
    "    def search(self, proj_id, _path, _query):\n",
    "        header = [\"Accept: application/json\"]\n",
    "        url = \"https://doaj.org/api/v2\"\n",
    "        #print(url+_path+ulp.quote(_query)+\"?page=1&pageSize=20&\"+header[1])\n",
    "        request = requests.get(url+_path+_query+\"?page=1&pageSize=20\")\n",
    "        \n",
    "        if (request.status_code == 200):\n",
    "            data = [proj_id, request.json()]\n",
    "            return data\n",
    "    \n",
    "    def searchArticles(self, proj_id, _query):\n",
    "        return self.search(proj_id, \"/search/articles/\", _query)\n",
    "    \n",
    "    def searchJournals(self, _query):\n",
    "        return self.search(proj_id, \"/search/journals/\", _query)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = DOAJSearch()\n",
    "results = api.search(123, '\"Lauren Fang\"')\n",
    "#print(results)\n",
    "print(\"Total hits: \" + str(results[1]['totalHits']))\n",
    "print(\"proj_id: \" +str(results[0]))\n",
    "hits = results[1]['totalHits']\n",
    "proj_id = str(results[0])\n",
    "#print(results)\n",
    "api.sendToDB(proj_id, results, hits)\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits: 5\n",
      "title: Distributed Regression Analysis Application in Large Distributed Data Networks: Analysis of Precision and Operational Performance\n",
      "doi: 10.2196/15073\n",
      "authors: \n",
      "Her, Qoua\n",
      "Malenfant, Jessica\n",
      "Zhang, Zilu\n",
      "Vilk, Yury\n",
      "Young, Jessica\n",
      "Tabano, David\n",
      "Hamilton, Jack\n",
      "Johnson, Ron\n",
      "Raebel, Marsha\n",
      "Boudreau, Denise\n",
      "Toh, Sengwee\n",
      "pub_year: 2020\n",
      "pub_month: 6\n",
      "keywords: None\n",
      "abstract: \n",
      "          \n",
      "            BackgroundA distributed data network approach combined with distributed regression analysis (DRA) can reduce the risk of disclosing sensitive individual and institutional information in multicenter studies. However, software that facilitates large-scale and efficient implementation of DRA is limited.\n",
      "            ObjectiveThis study aimed to assess the precision and operational performance of a DRA application comprising a SAS-based DRA package and a file transfer workflow developed within the open-source distributed networking software PopMedNet in a horizontally partitioned distributed data network.\n",
      "            MethodsWe executed the SAS-based DRA package to perform distributed linear, logistic, and Cox proportional hazards regression analysis on a real-world test case with 3 data partners. We used PopMedNet to iteratively and automatically transfer highly summarized information between the data partners and the analysis center. We compared the DRA results with the results from standard SAS procedures executed on the pooled individual-level dataset to evaluate the precision of the SAS-based DRA package. We computed the execution time of each step in the workflow to evaluate the operational performance of the PopMedNet-driven file transfer workflow.\n",
      "            ResultsAll DRA results were precise (<10âˆ’12), and DRA model fit curves were identical or similar to those obtained from the corresponding pooled individual-level data analyses. All regression models required less than 20 min for full end-to-end execution.\n",
      "            ConclusionsWe integrated a SAS-based DRA package with PopMedNet and successfully tested the new capability within an active distributed data network. The study demonstrated the validity and feasibility of using DRA to enable more privacy-protecting analysis in multicenter studies.\n",
      "full_text_url: https://medinform.jmir.org/2020/6/e15073\n"
     ]
    }
   ],
   "source": [
    "api = DOAJ()\n",
    "results = api.searchArticles('\"Jack Johnson\"')\n",
    "#print(results)\n",
    "print(\"Total hits: \" + str(results['total']))\n",
    "# title = str(results[1]['results'][i]['bibjson']['title'])\n",
    "# doi_array = str(results[1]['results'][i]['bibjson']['identifier'])\n",
    "# res = next((sub for sub in doi_array if sub['type'] == 'doi'), None)\n",
    "# doi = res['id']\n",
    "# author = results[1]['results'][i]['bibjson']['author'][j]['name']\n",
    "# pub_year = str(results[1]['results'][i]['bibjson']['year'])\n",
    "# pub_month = str(results[1]['results'][i]['bibjson']['month'])\n",
    "# keywords = str(results[1]['results'][i]['bibjson']['keywords'])\n",
    "# abstract = str(results[1]['results'][i]['bibjson']['abstract'])\n",
    "# full_text_url = str(results[1]['results'][i]['bibjson']['link']['url'])\n",
    "i=0\n",
    "title = str(results['results'][i]['bibjson']['title'])\n",
    "doi_array = results['results'][i]['bibjson']['identifier']\n",
    "res = next((sub for sub in doi_array if sub['type'] == 'doi'), None)\n",
    "doi = res['id']\n",
    "authors = results['results'][i]['bibjson9author']\n",
    "pub_year = str(results['results'][i]['bibjson']['year'])\n",
    "pub_month = str(results['results'][i]['bibjson']['month'])\n",
    "keywords = str(results['results'][i]['bibjson'].get('keywords'))\n",
    "abstract = str(results['results'][i]['bibjson']['abstract'])\n",
    "full_text_url = str(results['results'][i]['bibjson']['link'][0]['url'])\n",
    "print(\"title: \"+title)\n",
    "print(\"doi: \"+doi)\n",
    "print(\"authors: \")\n",
    "for author in authors:\n",
    "    print(author['name'])\n",
    "print(\"pub_year: \"+pub_year)\n",
    "print(\"pub_month: \"+pub_month)\n",
    "print(\"keywords: \"+keywords)\n",
    "print(\"abstract: \"+abstract)\n",
    "print(\"full_text_url: \"+full_text_url)\n",
    "# for result in results:\n",
    "#     print(result['authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
